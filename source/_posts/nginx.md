---
title: Nginx(初理解)
date: 2017-11-11 16:57:53
tags: Web服务器
categories: Web服务器
---

Nginx是一个高效,可靠的web服务和代理中间件.Nginx（发音同engine x）是一个网页服务器，它能反向代理HTTP, HTTPS, SMTP, POP3, IMAP的协议链接，以及一个负载均衡器和一个HTTP缓存。

- 高效体现在它能支持海量的并发请求.因此可以作为web服务器,它能够支持高达50000个并发连接数的响应.相比ApacheNginx使用更少资源支持更多的并发连接.
- 配置简洁.
- 能作为负载均衡服务器和邮件代理服务器.

<!--more -->

#### Nginx的实战场景:

1. 代理服务

代理又可以分为:
- 正向代理

正向代理的过程它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求.

![image](https://wx1.sinaimg.cn/mw1024/6b297ce5gy1fr77ggotuxj20hi09qgnt.jpg)

- 反向代理

反向代理就是一个服务端的负载均衡器.

反向代理的过程它隐藏了真实的服务端的地址,客户端发送请求到代理服务器,由代理服务器通过负载均衡决定将该请求发送到哪一台服务器中.

而且能从每一台服务器中获取不同的资源,Nginx还能充当一个统筹的角色.


![image](https://wx2.sinaimg.cn/mw1024/6b297ce5gy1fr77gttugyj20g509owg7.jpg)

==正向代理与反向代理的区别就是,正向代理隐藏的是客户端的真实地址,反向代理就是隐藏服务端的地址.==

2. 动态缓存
3. 动静分离
4. 负载均衡

#####  什么是负载均衡?

当多台服务器集群对外进行服务,但我们对外提供的访问入口只有一个,那么如何将请求分发到各种服务器,这就是负载均衡在做的事情.

![image](https://wx1.sinaimg.cn/mw1024/6b297ce5gy1fr7bve4vbzj20id076wf9.jpg)

##### 负载均衡的分类

负载均衡是一种计算机网络技术,用来在多台计算机(集群),CPU或其他资源中分配负载,以达到最佳化资源使用,最大化吞吐率,最小化响应时间,同时避免过载的目的.所以计算机技术的实现由很多种.最常用的有四层和七层负载均衡.

- 四层负载均衡

> 四层负载均衡工作在OSI模型的传输层，由于在传输层，只有TCP/UDP协议，这两种协议中除了包含源IP、目标IP以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器

- 七层负载均衡

> 七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、dns等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。

![image](https://wx1.sinaimg.cn/mw1024/6b297ce5gy1fr7c3bmoqaj20ej07hmxv.jpg)

但对于一般的应用来说,有了Nginx就可以了.Nginx可以用于七层负载均衡.但对于一些大的网站,一般会采用DNS+四层负载+七层负载的方式进行多次负载均衡.

##### 常见的负载均衡的算法(只介绍常用的几种)

首先负载均衡的算法分为两种:静态负载均衡算法和动态负载均衡

- 静态负载均衡算法:轮询,比率,优先权.

- 动态负载均衡算法:最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。

##### 轮询(Round-Robin)

> 轮询是默认的,每一个请求按顺序的分配到每台服务器上,如果后端服务器down掉,能自动剔除

##### Weight(权重)

> Weigth是设置权重,用于后端服务器性能不均衡的情况,访问比率等于权重之比:可以实现小流量分流,如果某台服务器挂了,则将流量分发到其他服务器上.

```
// 配置文件
upstream test {
server 192.168.109.5:81 weight=1;
servse 192.168.109.3:80 weight=5;
}

那么测试结果就会是109.5的被访问1次,109.3的会被访问5次,反复的循环
```

##### ip_hash

> 解决了session问题:每个请求按访问IP的Hash结果分配,这样每个访客都可以固定一个后端服务器了.

```
配置文件：
upstream test {
        ip_hash;
server 192.168.109.5:81;
servse 192.168.109.3:80;
}

// 测试结果:假如请求进来被分配到某一服务器中,那么之后请求都是访问同一台服务器.
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
192.168.109.5  It is work!
```
##### fair(第三方)

> 按照后端服务器的响应时间来分配请求,响应时间时间短的优先分配.

```
配置文件：
upstream test {
server 192.168.109.5:81;
servse 192.168.109.3:80;
fair;
}
```


5. Nginx与LUA的开发


> ngx_lua将Lua嵌入Nginx，可以让Nginx执行Lua脚本，并且高并发、非阻塞的处理各种请求。Lua内建协程，这样就可以很好的将异步回调转换成顺序调用的形式。ngx_lua在Lua中进行的IO操作都会委托给Nginx的事件模型，从而实现非阻塞调用。开发者可以采用串行的方式编写程序，ngx_lua会自动的在进行阻塞的IO操作时中断，保存上下文；然后将IO操作委托给Nginx事件处理机制，在IO操作完成后，ngx_lua会恢复上下文，程序继续执行，这些操作都是对用户程序透明的。 每个NginxWorker进程持有一个Lua解释器或者LuaJIT实例，被这个Worker处理的所有请求共享这个实例。每个请求的Context会被Lua轻量级的协程分割，从而保证各个请求是独立的。 ngx_lua采用“one-coroutine-per-request”的处理模型，对于每个用户请求，ngx_lua会唤醒一个协程用于执行用户代码处理请求，当请求处理完成这个协程会被销毁。每个协程都有一个独立的全局环境（变量空间），继承于全局共享的、只读的“comman data”。所以，被用户代码注入全局空间的任何变量都不会影响其他请求的处理，并且这些变量在请求处理完成后会被释放，这样就保证所有的用户代码都运行在一个“sandbox”（沙箱），这个沙箱与请求具有相同的生命周期。 得益于Lua协程的支持，ngx_lua在处理10000个并发请求时只需要很少的内存。根据测试，ngx_lua处理每个请求只需要2KB的内存，如果使用LuaJIT则会更少。所以ngx_lua非常适合用于实现可扩展的、高并发的服务。